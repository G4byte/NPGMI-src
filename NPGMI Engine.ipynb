{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73610847-198b-4c06-94d8-d32372a4994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fft import fft,fft2, fftfreq, fftshift, ifft\n",
    "from scipy.signal import oaconvolve\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from scipy.ndimage import rotate\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a27ea4-f5fc-4365-8fa8-730218c191bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assert_ndarr(container):\n",
    "\"\"\"\n",
    "    Ensures that the input is cast to a numpy array.\n",
    "\n",
    "    Args:\n",
    "        container: an array-like object containing some values.\n",
    "    Returns:\n",
    "        The contents of container cast to a numpy array.\n",
    "    \n",
    "\"\"\"\n",
    "    \n",
    "    if type(container) == np.ndarray and container.ndim > 0:\n",
    "        return container\n",
    "    elif type(container) == list:\n",
    "        return np.squeeze(container)\n",
    "    elif container is None:\n",
    "        raise TypeError(\"Input is None\")\n",
    "    return np.array([container])\n",
    "\n",
    "def get_chi_sq(data, modelled, uncert):\n",
    "\"\"\"\n",
    "    Ensures that the input is cast to a numpy array.\n",
    "\n",
    "    Args:\n",
    "        container: an array-like object containing some values.\n",
    "    Returns:\n",
    "        The contents of container cast to a numpy array.\n",
    "    \n",
    "\"\"\"\n",
    "    return np.sum((data - modelled)**2 / (uncert**2))\n",
    "\n",
    "def print_shapes(*arrs):\n",
    "    for arr in arrs:\n",
    "        print(arr.shape, end = \" \")\n",
    "    print(\"\\n\")\n",
    "\n",
    "def normalize_profile(profile, axis = -1,bounds = [-1,1]):\n",
    "    profile, profile_min, profile_max = force_broadcast(profile, np.amin(profile,axis=axis), np.amax(profile,axis=axis))\n",
    "    return (bounds[1] - bounds[0]) * (profile - profile_min)/(profile_max - profile_min) + bounds[0]\n",
    "\n",
    "def get_param_axis(ndarr, a):\n",
    "    if type(a) == np.ndarray:\n",
    "        a = a.squeeze()\n",
    "        if a.ndim > 0:\n",
    "            return ndarr.shape.index(a.shape[-1])\n",
    "        else:\n",
    "            return None\n",
    "    return ndarr.shape.index(a)\n",
    "\n",
    "def flatten_after_axis(*arrs, axis = -2):\n",
    "    return [np.reshape(arr, (*arr.shape[:axis], np.prod(arr.shape[axis:]))) for arr in arrs]\n",
    "\n",
    "def flatten_after_axis_2d(arr, axis = -2):\n",
    "    return np.reshape(arr, (*arr.shape[:2*axis], np.prod(arr.shape[2*axis:axis]), np.prod(arr.shape[axis:])))\n",
    "\n",
    "def retain_shape_after_index(arr,locs, flat_index = False):\n",
    "    arr = assert_ndarr(arr)\n",
    "    if not flat_index:\n",
    "        return arr[...,locs].reshape(*(arr.shape[:-1]),-1)\n",
    "    return arr[locs].reshape(*(arr.shape[:-1]),-1)\n",
    "\n",
    "\n",
    "def generate_stepfunc(width,xbin = None, n_pts = None, shift = 0):\n",
    "    # stepfunc_x = np.linspace(-shift,10*width-shift,int(10*width/xbin)) if n_pts is None else np.linspace(-shift,10*width-shift,n_pts)\n",
    "    # return np.heaviside(stepfunc_x - 4.5*width,1) - np.heaviside(stepfunc_x - 5.5*width,1)\n",
    "#     behaves differently for source gratings, needs further work\n",
    "    stepfunc_x = np.linspace(-shift,width-shift + xbin,int(width/xbin) + 1) if n_pts is None else np.linspace(-shift,width-shift + xbin,n_pts)\n",
    "    return np.heaviside(stepfunc_x- xbin,1) - np.heaviside(stepfunc_x - width,1)\n",
    "\n",
    "def generate_source_grating(period, duty_cycle, binsize, n_periods = 50):\n",
    "    single_source_x = np.linspace(0,period, int(period/binsize)).squeeze()\n",
    "    single_source = np.heaviside(single_source_x,1) - np.heaviside(single_source_x - duty_cycle*period,1)\n",
    "    source = assert_ndarr([*np.tile(single_source, n_periods)])\n",
    "    return source\n",
    "\n",
    "def generate_single_source(period, duty_cycle, binsize, n_periods, current_period):\n",
    "    single_source_x = np.linspace(0,(n_periods*period), int((n_periods*period)/binsize)+1)\n",
    "    single_source = np.heaviside(single_source_x - (current_period*period),1)\\\n",
    "                    - np.heaviside(single_source_x - (current_period*period + duty_cycle*period),1)\n",
    "    return single_source\n",
    "\n",
    "def sinc(x):\n",
    "    x_is_0 = x == 0\n",
    "    out = np.sin(x)\n",
    "    x[x_is_0] = 1\n",
    "    out /= x\n",
    "    out[x_is_0] = 1\n",
    "\n",
    "    return out\n",
    "\n",
    "def squareFT(width,k,shift = 0):\n",
    "    return -np.exp(-1j*shift)*sinc(width*k/2)\n",
    "\n",
    "def source_grating_FT(sg,target_freqs, xbin):\n",
    "\n",
    "    padded = np.pad(sg, 10*len(sg))\n",
    "    ft = fft(padded, axis = -1, norm=\"forward\")\n",
    "    freqs = get_freqs(ft,get_param_axis(ft,padded),ft.shape[-1]*xbin)\n",
    "    # plt.plot(freqs, np.abs(ft))\n",
    "    # plt.xlim(-2*pi / 300e-6, 2*pi / 300e-6)\n",
    "    # plt.show()\n",
    "\n",
    "    target_freqs, freqs = force_broadcast(target_freqs, freqs)\n",
    "\n",
    "    return ft[np.argmin(np.abs(freqs - target_freqs), axis = -1)]\n",
    "    \n",
    "    \n",
    "\n",
    "def cosine_func(x,A,B,p,phi):\n",
    "    return A + B*np.cos(2*np.pi*x/p + phi)\n",
    "\n",
    "def sphere_p_s(r_sphere, p_g, const):\n",
    "    return const * (p_g**2.5) / (r_sphere**1.5)\n",
    "\n",
    "def sphere_autocorrelation_func(x,r_sphere):\n",
    "    zeta = x / r_sphere\n",
    "    return np.real(np.sqrt(1 - (zeta/2)**2)*(1+ zeta**2 / 8) + zeta**2/2 *\\\n",
    "            (1 - (zeta/4)**2) * np.log(zeta / (2 + np.sqrt(4 - zeta**2))))\n",
    "    # return np.real(np.exp(-9/8 * (zeta)**2))\n",
    "\n",
    "def max_index(ndarr):\n",
    "    return np.unravel_index(np.argmax(ndarr),ndarr.shape)\n",
    "\n",
    "def min_index(ndarr):\n",
    "    return np.unravel_index(np.argmin(ndarr),ndarr.shape)\n",
    "\n",
    "def lowpass(data, minperiod, pxlsize, order):\n",
    "\n",
    "    normal_cutoff = pxlsize/minperiod\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    " \n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def apply_over_bins(func, arr_to_bin, bin_width, axis = None):\n",
    "    n_bins = arr_to_bin.shape[0] // bin_width\n",
    "    ret = []\n",
    "    for i in range(n_bins+1):\n",
    "        ret.append(func(arr_to_bin[i*bin_width:(i+1)*bin_width], axis = axis))\n",
    "    return ret\n",
    "\n",
    "def process_tfl(imgarr, rot_deg, medfilt_window = None):\n",
    "    imgarr[~np.isfinite(imgarr)] = 0\n",
    "    ycut,xcut = (np.array(imgarr.shape) * np.abs(np.tan(np.radians(rot_deg)))).astype(int)\n",
    "    if medfilt_window is not None:\n",
    "        # return medfilt2d(np.array(Image.fromarray(imgarr).rotate(rot_deg))[ycut:-ycut, xcut: -xcut],medfilt_window)\n",
    "        return medfilt2d(np.array(Image.fromarray(imgarr).rotate(rot_deg)),medfilt_window)\n",
    "\n",
    "    else:\n",
    "        # return np.array(Image.fromarray(imgarr).rotate(rot_deg))[ycut: -ycut, xcut: -xcut]\n",
    "        return np.array(Image.fromarray(imgarr).rotate(rot_deg))\n",
    "\n",
    "def lin_func(d,d0,L,L0,p):\n",
    "    return (d - d0)/((L-L0)*p)\n",
    "\n",
    "def grating_equation(xarr,p, phase_offset):\n",
    "    return np.sign(np.sin(2*np.pi*xarr/p + phase_offset))\n",
    "\n",
    "def grating_equation_2d(xarr,yarr,px,py):\n",
    "    \n",
    "    return np.sign(np.cos(2*pi*xarr/px) + np.cos(2*pi*yarr/py) - 1)\n",
    "\n",
    "def maxmincont(arr):\n",
    "    return (np.amax(arr,axis = -1) - np.amin(arr,axis = -1))/(np.amax(arr,axis = -1) + np.amin(arr,axis = -1))\n",
    "\n",
    "def get_freqs(ft_like, axis, real_signal_length):\n",
    "    real_signal_length = assert_ndarr(real_signal_length)\n",
    "    return 2*np.pi*np.squeeze([fftfreq(ft_like.shape[axis],size/ft_like.shape[axis]) for size in real_signal_length]) \n",
    "\n",
    "def lookup_inds(vals_to_find, available_vals):\n",
    "    lookup_vals = np.intersect1d(vals_to_find,available_vals, assume_unique = True)\n",
    "\n",
    "    return np.squeeze(np.nonzero(np.isin(available_vals,lookup_vals)))\n",
    "\n",
    "\n",
    "\n",
    "def get_complement_inds(arr,arr_complement,target):\n",
    "    \n",
    "    start = True\n",
    "\n",
    "    for i in range(arr.shape[-1]):\n",
    "#        if i % 10 == 0:\n",
    "#            clear_output(wait = True)\n",
    "#            print(\"%.2f %% done rolling\" % (100*i/arr.shape[-1]))\n",
    "        \n",
    "        rolled_sum = arr + np.roll(arr_complement,-i, axis = -1)\n",
    "        bool_where_target = np.isclose(rolled_sum, target)\n",
    "        \n",
    "        if np.any(bool_where_target):\n",
    "            \n",
    "            nonzero = assert_ndarr(np.squeeze(np.nonzero(bool_where_target)))\n",
    "            if start:\n",
    "                arr_inds, arr_complement_inds = nonzero, (nonzero + i) % arr.shape[-1]\n",
    "                start = False\n",
    "            else:\n",
    "                arr_inds = np.concatenate((arr_inds,nonzero), axis = -1)\n",
    "                arr_complement_inds = np.concatenate((arr_complement_inds,(nonzero + i)),\\\n",
    "                                    axis = -1) % arr.shape[-1]\n",
    "                \n",
    "            # print(arr[...,arr_inds] + arr_complement[...,arr_complement_inds])\n",
    "            \n",
    "    return [np.squeeze(arr_inds).astype(int),np.squeeze(arr_complement_inds).astype(int)]\n",
    "\n",
    "\n",
    "def get_a_final(a,k,target):\n",
    "\n",
    "    a_conj, k_conj = np.conj(a), -k\n",
    "\n",
    "    indices, conj_indices = get_complement_inds(k,k_conj,target) \n",
    "    \n",
    "    a = np.sum(retain_shape_after_index(a,indices) * retain_shape_after_index(a_conj,\\\n",
    "        conj_indices), axis = -1)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def get_a_final_2d(a,kx,ky,targetx,targety):\n",
    "\n",
    "    a_conj, kx_conj, ky_conj = np.conj(a), -kx, -ky\n",
    "    \n",
    "    \n",
    "        \n",
    "    indicesx, conj_indicesx = get_complement_inds(kx,kx_conj,targetx)\n",
    "    indicesy, conj_indicesy = get_complement_inds(ky,ky_conj,targety)\n",
    "    \n",
    "    if (np.squeeze(targetx) == 0) & (np.squeeze(targety) == 0):\n",
    "        \n",
    "        a_zero = np.sum(a[...,indicesx[:,None], indicesy[None,:]] * a_conj[...,conj_indicesx[:,None], conj_indicesy[None,:]], axis = (-2,-1))\n",
    "\n",
    "        return a_zero\n",
    "\n",
    "    else:\n",
    "        x_zero_indices, conj_x_zero_indices = get_complement_inds(kx,kx_conj,0)\n",
    "        y_zero_indices, conj_y_zero_indices = get_complement_inds(ky,ky_conj,0)\n",
    "        \n",
    "    \n",
    "        a_targetx = np.sum(a[...,indicesx[:,None],y_zero_indices[None,:]] * a_conj[...,conj_indicesx[:,None],conj_y_zero_indices[None,:]], axis = (-2,-1))\n",
    "\n",
    "        a_targety = np.sum(a[...,x_zero_indices[:,None],indicesy[None,:]] * a_conj[...,conj_x_zero_indices[:,None],conj_indicesy[None,:]], axis = (-2,-1))\n",
    "\n",
    "\n",
    "        return [a_targetx,a_targety]\n",
    "\n",
    "\n",
    "\n",
    "def fork_get_regions(nd_intens, xcam, ycam, pg, L, di):\n",
    "    # so stupid and rushed \n",
    "    imgshp = nd_intens.shape[-2:]\n",
    "    pm_in_pts = int((L*pg/di)/xcam * imgshp[0])\n",
    "    starty = int(imgshp[1]/20)\n",
    "    \n",
    "    left_startx = np.argmax(nd_intens[..., :pm_in_pts,starty], axis = -1)\n",
    "    right_startx = np.argmax(nd_intens[..., imgshp[0] - pm_in_pts:,starty], axis = -1)\n",
    "    \n",
    "    startx_dist = np.abs(right_startx - left_startx)\n",
    "    \n",
    "    xl, yl = left_startx, starty\n",
    "    xr, yr = right_startx, starty\n",
    "    \n",
    "    for step in range(imgshp[1] - 2*starty):\n",
    "        gradxl = nd_intens[...,xl + 1,yl] - nd_intens[...,xl - 1, yl]\n",
    "        gradyl = nd_intens[...,xl,yl + 1] - nd_intens[...,xl,yl - 1]\n",
    "        gradl_mag = (gradxl**2 + gradyl**2)**0.5\n",
    "        \n",
    "        gradxr = nd_intens[...,xr + 1,yr] - nd_intens[...,xr - 1, yr]\n",
    "        gradyr = nd_intens[...,xr,yr + 1] - nd_intens[...,xr,yr - 1]\n",
    "        gradr_mag = (gradxr**2 + gradyr**2)**0.5\n",
    "        \n",
    "        if np.all(gradl_mag == 0) or np.all((np.rint(gradxl/gradl_mag) == 0) & (np.rint(gradyl/gradl_mag) == 0)):\n",
    "            stepxl,stepyl = 1, 1\n",
    "        else:\n",
    "            stepxl, stepyl = np.rint(gradxl/gradl_mag), np.rint(gradyl/gradl_mag)\n",
    "            \n",
    "        if np.all(gradr_mag == 0) or np.all((np.rint(gradxr/gradr_mag) == 0) & (np.rint(gradyr/gradr_mag) == 0)):\n",
    "            stepxr,stepyr = -1, 1\n",
    "        else:\n",
    "            stepxr, stepyr = np.rint(gradxr/gradr_mag), np.rint(gradyr/gradr_mag)\n",
    "        \n",
    "        xl += stepxl\n",
    "        yl += stepyl\n",
    "        xr += stepxr\n",
    "        yr += stepyr\n",
    "    \n",
    "    endx_dist = np.abs(xr - xl)\n",
    "    \n",
    "    if startx_dist > endx_dist:\n",
    "        fork_region = [left_startx,right_startx,starty, starty*5]\n",
    "        nofork_region = [xl,xr,yl,imgshp[1]]\n",
    "    else:\n",
    "        fork_region = [xl,xr,yl,imgshp[1]]\n",
    "        nofork_region = [left_startx,right_startx,starty, starty*5]\n",
    "    \n",
    "    return [fork_region, nofork_region]\n",
    "\n",
    "def best_fit_moire_period(func,xdata,intens,pg,L,d):\n",
    "    \n",
    "    def pfit(func,x,intens, p0):\n",
    "        params, cov = curve_fit(func,x,intens, p0, maxfev = 20000) \n",
    "        return np.array([params,np.sqrt(np.diag(cov))])\n",
    "        \n",
    "    pmoire_dist = np.linspace(0.875*L * pg/d, 1.125*L*pg/d, 51).squeeze()\n",
    "\n",
    "    A,B,phi = np.mean(intens), np.amax(intens) - np.mean(intens), 0\n",
    "\n",
    "    all_params_with_error = np.swapaxes(jb.Parallel(n_jobs = -1)(jb.delayed(pfit)(func,xdata,intens, p0 = [A,B,pmoire,phi])\\\n",
    "                            for pmoire in pmoire_dist), -2,0)\n",
    "    allparams, allerror = all_params_with_error\n",
    "\n",
    "    return np.array(allparams[np.argmin(allerror[...,2])])\n",
    "\n",
    "def best_fit_moire_period_with_error(func,xdata,intens,pg,L,d, use_abs_sigma = True):\n",
    "    \n",
    "    def pfit(func,x,intens, p0):\n",
    "        if use_abs_sigma:\n",
    "            params, cov = curve_fit(func,x,intens, p0, maxfev = 20000, sigma = np.sqrt(intens), absolute_sigma = True) \n",
    "        else:\n",
    "            params, cov = curve_fit(func,x,intens, p0, maxfev = 20000)\n",
    "            \n",
    "        return np.array([params,np.sqrt(np.diag(cov))])\n",
    "        \n",
    "    pmoire_dist = np.linspace(0.875*L * pg/d, 1.125*L*pg/d, 51).squeeze()\n",
    "\n",
    "    A,B,phi = np.mean(intens), np.amax(intens) - np.mean(intens), 0\n",
    "\n",
    "    all_params_with_error = np.swapaxes(jb.Parallel(n_jobs = -1)(jb.delayed(pfit)(func,xdata,intens, p0 = [A,B,pmoire,phi])\\\n",
    "                            for pmoire in pmoire_dist), -2,0)\n",
    "    allparams, allerror = all_params_with_error\n",
    "\n",
    "    return [np.array(allparams[np.argmin(allerror[...,2])]), allerror[np.argmin(allerror[...,2])]]\n",
    "\n",
    "def force_broadcast(*arrs, nonunique_lengths = [], nonunique_occurrences = [], desired_nonunique_arr_ax = [[]]):\n",
    "    \n",
    "    \n",
    "    arrs = [assert_ndarr(arr).squeeze() for arr in arrs]\n",
    "\n",
    "    output_lengths = []\n",
    "\n",
    "    for i in range(len(arrs)):\n",
    "        for j in range(arrs[i].ndim):\n",
    "            length = arrs[i].shape[j]\n",
    "            if length in nonunique_lengths and output_lengths.count(length) <\\\n",
    "                nonunique_occurrences[nonunique_lengths.index(length)]:\n",
    "                for _ in range(nonunique_occurrences[nonunique_lengths.index(length)]):\n",
    "                    output_lengths.append(length) \n",
    "\n",
    "            elif length not in output_lengths:\n",
    "                output_lengths.append(length) \n",
    "    \n",
    "    output_lengths = [i for i in output_lengths if i not in nonunique_lengths] +\\\n",
    "                    [i for i in output_lengths if i in nonunique_lengths]\n",
    "\n",
    "    common_ndim = len(output_lengths)\n",
    "    axes = np.arange(common_ndim)\n",
    "    # lengths_copy = output_lengths.copy()\n",
    "    \n",
    "    newshapes = np.ones((len(arrs),len(output_lengths)),dtype = int)\n",
    "    \n",
    "    if nonunique_lengths != []:\n",
    "        for i, length in enumerate(nonunique_lengths):\n",
    "            for (ind, ax) in desired_nonunique_arr_ax[i]:\n",
    "                newshapes[ind,ax] = length\n",
    "    \n",
    "    \n",
    "    for i, arr in enumerate(arrs):\n",
    "        shp = arrs[i].shape\n",
    "        for j, length in enumerate(output_lengths):\n",
    "            if length in shp and length not in nonunique_lengths:\n",
    "                newshapes[i,j] = length\n",
    "        \n",
    "        arrs[i] = np.reshape(arrs[i], newshapes[i].astype(int))\n",
    "            \n",
    "    new_arrs = [assert_ndarr(arr) for arr in arrs]\n",
    "    return new_arrs \n",
    "\n",
    "def force_equal_dims(top, btm):\n",
    "    final_ndim = max(top.ndim,btm.ndim)\n",
    "    for _ in range(final_ndim - top.ndim):\n",
    "        top = np.expand_dims(top,-1)\n",
    "    for _ in range(final_ndim - btm.ndim):\n",
    "        btm = np.expand_dims(btm,0)\n",
    "    return [top,btm]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sd stands for setup dictionary\n",
    "class PGMI:\n",
    "#     !to-do eventually: replace integer references to axes with string variable names (using numpy record arrays or Pandas Index ?) i.e. map input\n",
    "#     strings to array axes and define class methods that get values/do something along input axes (np.apply_along_axis, np.meshgrid might be useful)\n",
    "#     might also be worthwhile to predefine the entire dimensionality of the simulation if possible\n",
    "\n",
    "    def __init__(self, apts_dict, sd):\n",
    "\n",
    "        self.apts_dict = apts_dict\n",
    "        self.N_objects = len(apts_dict)\n",
    "        \n",
    "        for n, Apparatus in enumerate(self.apts_dict.values()):\n",
    "            setattr(Apparatus,\"apts_num\", n+1)\n",
    "        \n",
    "        for key, value in sd.items():\n",
    "            setattr(self, key, assert_ndarr(value))\n",
    "        \n",
    "        self.slitxflag = False\n",
    "        self.slityflag = False\n",
    "\n",
    "        if sd.get(\"slitx\") is not None:\n",
    "            self.slitxflag = True\n",
    "\n",
    "\n",
    "        if sd.get(\"slity\") is not None:\n",
    "            self.slityflag = True\n",
    "            \n",
    "        \n",
    "\n",
    "        self.stepresx = generate_stepfunc(self.resx,self.xbin).squeeze()\n",
    "        self.stepresy = generate_stepfunc(self.resy,self.ybin).squeeze()\n",
    "                \n",
    "        \n",
    "        self.k0 = 2*np.pi/self.lam\n",
    "        self.neu_spec = None\n",
    "        \n",
    "        for Apparatus in self.apts_dict.values():\n",
    "            if type(Apparatus) == RectGrating2D:\n",
    "                self.px,self.py = Apparatus.px, Apparatus.py\n",
    "        \n",
    "\n",
    "        if sd.get(\"source_period\") is not None:\n",
    "            self.source_grating_flag = True\n",
    "            self.source_grating = generate_source_grating(self.source_period,self.duty_cycle,self.xbin, n_periods= 10)\n",
    "        else:\n",
    "            self.source_grating_flag = False\n",
    "        \n",
    "        if sd.get(\"gravity\") is None:\n",
    "            self.gravity = False\n",
    "        \n",
    "        elif self.gravity:\n",
    "            # self.g = 9.80665\n",
    "            g_nominal = 9.80665\n",
    "            g_spread = 0.25\n",
    "            g_res = 0.01\n",
    "            self.g = np.arange(g_nominal - g_spread, g_nominal + g_spread + g_res, g_res)\n",
    "            self.planck_h = 6.62607015e-34\n",
    "            self.neu_mass = 1.6749275e-27\n",
    "            # self.grav_yshift = self.g/2 * (self.L*self.neu_mass*self.lam/self.planck_h)**2\n",
    "            self.C_0_x = 0\n",
    "            self.C_0_y = 0 # could be setup parameter in future but can be 0 w.l.g I think\n",
    "            \n",
    "            self.d, self.lam, self.g, L2 = force_broadcast(self.d, self.lam, self.g, list(self.apts_dict.values())[-1].L2)\n",
    "            \n",
    "            self.grav_xshift = np.pi * self.g * np.sin(np.radians(self.cam_rotdeg)) * self.d / (self.L * self.px) * \\\n",
    "                        (L2 * self.neu_mass * self.lam / self.planck_h)**2 + self.C_0_x\n",
    "            \n",
    "            self.grav_yshift = np.pi * self.g * np.cos(np.radians(self.cam_rotdeg)) * self.d / (self.L * self.py) * \\\n",
    "                        (L2 * self.neu_mass * self.lam / self.planck_h)**2 + self.C_0_y\n",
    "            \n",
    "            self.d, self.lam = self.d.squeeze(), self.lam.squeeze()\n",
    "            \n",
    "        if sd.get(\"bin_lam\") is None:\n",
    "            self.bin_lam = False\n",
    "            \n",
    "        if sd.get(\"Ioffset\") is None:\n",
    "            self.Ioffset = None \n",
    "            \n",
    "        \n",
    "    def get_apts(self):\n",
    "        return self.apts_dict\n",
    "    \n",
    "    def get_values(self):\n",
    "        return vars(self)\n",
    "    \n",
    "    def get_value(self,key):\n",
    "        return vars(self)[key]\n",
    "\n",
    "    def propagate_to(self, key):\n",
    "        Apparatus = self.get_apts()[key]\n",
    "        \n",
    "        self.neu_spec = Apparatus.propagate(self.k0, self.neu_spec)\n",
    "\n",
    "\n",
    "    def generate_after(self, key):\n",
    "        Apparatus = self.get_apts()[key]\n",
    "        \n",
    "        if Apparatus.is2d:\n",
    "            kx_moire_vals = (2*np.pi/(self.L*self.px/self.d)).squeeze()\n",
    "            ky_moire_vals = (2*np.pi/(self.L*self.py/self.d)).squeeze()\n",
    "            \n",
    "            a, kx, ky = self.neu_spec\n",
    "            kx, ky = np.real_if_close(kx.squeeze()), np.real_if_close(ky.squeeze())\n",
    "            \n",
    "            a, kx, ky = assert_ndarr(flatten_after_axis_2d(a)), assert_ndarr(flatten_after_axis(kx)), assert_ndarr(flatten_after_axis(kx))\n",
    "            \n",
    "            \n",
    "            print_shapes(a, kx, ky)\n",
    "            if self.plam.squeeze().ndim > 0:\n",
    "                kx = np.moveaxis(kx,get_param_axis(kx,self.plam),0)[0]\n",
    "                ky = np.moveaxis(ky,get_param_axis(ky,self.plam),0)[0]\n",
    "                # moire frequency is independent of wavelength, makes indexing much simpler\n",
    "            \n",
    "            if self.d.squeeze().ndim > 0:\n",
    "                a, kx, ky = np.moveaxis(a,get_param_axis(a,self.d), 0), np.moveaxis(kx,get_param_axis(kx,kx_moire_vals), 0),\\\n",
    "                            np.moveaxis(ky,get_param_axis(ky,ky_moire_vals), 0)\n",
    "                \n",
    "                print_shapes(a, kx, ky)\n",
    "\n",
    "                a_moirex, a_moirey = get_a_final_2d(a,kx[tuple(np.zeros(kx.ndim - 1, dtype = int))],\\\n",
    "                                    ky[tuple(np.zeros(ky.ndim - 1, dtype = int))],kx_moire_vals[0], ky_moire_vals[0])\n",
    "                # indices are the same for all d, so just pick k corresponding to the first one for speed\n",
    "\n",
    "                a_zero = get_a_final_2d(a,kx[tuple(np.zeros(kx.ndim - 1, dtype = int))],ky[tuple(np.zeros(ky.ndim - 1, dtype = int))],0,0)\n",
    "            else:\n",
    "                a_moirex, a_moirey = get_a_final_2d(a,kx,ky,kx_moire_vals, ky_moire_vals)\n",
    "                \n",
    "                a_zero = get_a_final_2d(a,kx,ky,0,0)\n",
    "                \n",
    "\n",
    "            self.all_a, self.all_kx, self.all_ky = a, kx, ky\n",
    "\n",
    "            k_zero = np.zeros_like(kx_moire_vals)\n",
    "\n",
    "            # print(\"past get_a_k_final\")\n",
    "            \n",
    "            \n",
    "            kx = np.array([k_zero,kx_moire_vals]) \n",
    "            ky = np.array([k_zero,ky_moire_vals]) \n",
    "\n",
    "            \n",
    "            if self.gravity:\n",
    "                kx, self.slitx, self.grav_xshift = force_broadcast(kx,self.slitx, self.grav_xshift)\n",
    "                ky, self.slity, self.grav_yshift = force_broadcast(ky,self.slity, self.grav_yshift)\n",
    "                slitxft = squareFT(self.slitx, kx, shift = self.grav_xshift)\n",
    "                pxlxft = squareFT(self.resx, kx, shift = self.grav_xshift)\n",
    "                slityft = squareFT(self.slity, ky, shift = self.grav_yshift)\n",
    "                pxlyft = squareFT(self.resy, ky, shift = self.grav_yshift)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                slitxft = squareFT(self.slitx, kx)\n",
    "                pxlxft = squareFT(self.resx, kx)\n",
    "                slityft = squareFT(self.slity, ky)\n",
    "                pxlyft = squareFT(self.resy, ky)\n",
    "            \n",
    "                    \n",
    "            a_zero, slitxft_zero, pxlxft_zero, slityft_zero, pxlyft_zero = force_broadcast(a_zero, slitxft[0], pxlxft[0],\\\n",
    "                                                                            slityft[0],pxlyft[0])\n",
    "            a_zero = a_zero * slitxft_zero * pxlxft_zero * slityft_zero * pxlyft_zero\n",
    "            \n",
    "            \n",
    "            a_moirex, slitxft_moire, pxlxft_moire = force_broadcast(a_moirex, slitxft[1], pxlxft[1])\n",
    "            a_moirex = a_moirex * slitxft_moire * pxlxft_moire\n",
    "            \n",
    "            \n",
    "            a_moirey, slityft_moire, pxlyft_moire = force_broadcast(a_moirey, slityft[1],pxlyft[1])\n",
    "\n",
    "            \n",
    "            a_moirey = a_moirey * slityft_moire * pxlyft_moire\n",
    "            \n",
    "            \n",
    "            if self.bin_lam:\n",
    "                a_zero, a_moirex, a_moirey, self.plam = force_broadcast(a_zero, a_moirex, a_moirey, self.plam)\n",
    "                a_zero, a_moirex, a_moirey = a_zero*self.plam,a_moirex*self.plam,a_moirey*self.plam\n",
    "                \n",
    "                bins = np.arange(round(np.min(self.lam/self.lam_binsize)), \\\n",
    "                        round(np.max(self.lam/self.lam_binsize))+1,1) * self.lam_binsize\n",
    "                \n",
    "                print(\"Wavelength bins:\", bins)\n",
    "                \n",
    "                bin_ind = np.argmin(np.abs(self.lam[:,None] - bins[None,:]), axis = 0)\n",
    "                \n",
    "                lam_axis = get_param_axis(a_zero, self.lam)\n",
    "                \n",
    "                \n",
    "                a_zero, a_moirex, a_moirey = np.moveaxis(a_zero, lam_axis, 0), np.moveaxis(a_moirex, lam_axis, 0),\\\n",
    "                                            np.moveaxis(a_moirey, lam_axis, 0)\n",
    "                \n",
    "                \n",
    "                a_zero   = np.moveaxis([np.sum(a_zero[bin_ind[i]:bin_ind[i+1]],   axis = 0) for i in range(len(bins)-1)],0,lam_axis)\n",
    "                a_moirex = np.moveaxis([np.sum(a_moirex[bin_ind[i]:bin_ind[i+1]], axis = 0) for i in range(len(bins)-1)],0,lam_axis)\n",
    "                a_moirey = np.moveaxis([np.sum(a_moirey[bin_ind[i]:bin_ind[i+1]], axis = 0) for i in range(len(bins)-1)],0,lam_axis)\n",
    "                \n",
    "\n",
    "            elif self.sum_lam:\n",
    "                a_zero, a_moirex, a_moirey, self.plam = force_broadcast(a_zero, a_moirex, a_moirey, self.plam)\n",
    "                a_zero, a_moirex, a_moirey = a_zero*self.plam,a_moirex*self.plam,a_moirey*self.plam\n",
    "                    \n",
    "                a_zero, a_moirex, a_moirey = np.sum(a_zero*self.plam, axis = get_param_axis(a_zero,self.plam)),\\\n",
    "                                            np.sum(a_moirex*self.plam, axis = get_param_axis(a_moirex,self.plam)),\\\n",
    "                                            np.sum(a_moirey*self.plam, axis = get_param_axis(a_moirey,self.plam))\n",
    "            \n",
    "            \n",
    "            self.contrast_x = np.abs(2*a_moirex/a_zero)\n",
    "            self.contrast_y = np.abs(2*a_moirey/a_zero)\n",
    "            self.phase_x = np.arctan2(np.imag(a_moirex), np.real(a_moirex))\n",
    "            self.phase_y = np.arctan2(np.imag(a_moirey), np.real(a_moirey))\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            k_moire_vals = (2*np.pi/(self.L*self.p/self.d)).squeeze()\n",
    "\n",
    "            a, k = flatten_after_axis(*self.neu_spec,axis = -Apparatus.apts_num)\n",
    "\n",
    "            k = np.real_if_close(k)\n",
    "\n",
    "            # print_shapes(k, k_moire_vals)\n",
    "\n",
    "            if self.plam.squeeze().ndim > 0:\n",
    "                k = np.moveaxis(k,get_param_axis(k,self.plam),0)[0]\n",
    "                # moire frequency is independent of wavelength, makes indexing much simpler\n",
    "\n",
    "            if self.d.squeeze().ndim > 0:\n",
    "                a, k = np.moveaxis(a,get_param_axis(a,self.d), 0), np.moveaxis(k,get_param_axis(k,k_moire_vals), 0)\n",
    "                # indices are the same for all d, so just pick k corresponding to the first one for speed\n",
    "\n",
    "                a_moire = get_a_final(a,k[tuple(np.zeros(k.ndim - 1, dtype = int))],k_moire_vals[tuple(np.zeros(k_moire_vals.ndim, dtype = int))])\n",
    "                a_zero = get_a_final(a,k[tuple(np.zeros(k.ndim - 1, dtype = int))],0)\n",
    "\n",
    "            else:\n",
    "                a_moire = get_a_final(a,k,k_moire_vals)\n",
    "                a_zero = get_a_final(a,k,0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            k_zero = np.zeros_like(k_moire_vals)\n",
    "\n",
    "            # print(\"past get_a_k_final\")\n",
    "            a, k = np.array([a_zero,a_moire]), np.array([k_zero,k_moire_vals])\n",
    "            # print_shapes(a,k)\n",
    "\n",
    "            if self.sum_lam:\n",
    "                a, self.plam = force_broadcast(a, self.plam)\n",
    "\n",
    "                a = np.sum(a*self.plam, axis = get_param_axis(a,self.plam))\n",
    "\n",
    "            if self.source_grating_flag:\n",
    "                slitxft = source_grating_FT(self.source_grating,k, self.xbin)\n",
    "            else:\n",
    "                slitxft = squareFT(self.slitx, k)\n",
    "            pxlft = squareFT(self.resx, k)\n",
    "\n",
    "            a, slitxft, pxlft = force_broadcast(a, slitxft, pxlft)\n",
    "            a *= slitxft * pxlft\n",
    "            # technically don't need to multiply a_zero by the slit/pxl sinc functions because sinc(k_zero) = 1\n",
    "\n",
    "            self.contrast = np.abs(2*a[1]/a[0])\n",
    "    \n",
    "    def intensity_fit(self, key):\n",
    "        \n",
    "        Apparatus = self.get_apts()[key]\n",
    "        \n",
    "        self.batches = int(self.batches)\n",
    "\n",
    "        \n",
    "        self.x = self.x[:len(self.x) - len(self.x) % self.batches]\n",
    "\n",
    "        xbatches = np.array([self.x[i*len(self.x)//self.batches:(i+1)*len(self.x)//self.batches] for i in range(self.batches)])\n",
    "        \n",
    "        if Apparatus.is2d:\n",
    "            \n",
    "            self.y = self.y[:len(self.y) - len(self.y) % self.batches]\n",
    "\n",
    "            ybatches = np.array([self.y[i*len(self.y)//self.batches:(i+1)*len(self.y)//self.batches] for i in range(self.batches)])\n",
    "\n",
    "            # self.raw = np.array([[Apparatus.generate_raw_intensity(self.neu_spec,xi,\\\n",
    "            #             yi, i, self.batches) for yi in ybatches] for i, xi in enumerate(xbatches)])\n",
    "            self.raw = np.array(jb.Parallel(n_jobs = -1, prefer = \"threads\")(jb.delayed(Apparatus.generate_raw_intensity)(self.neu_spec,xi,\\\n",
    "                        yi, i, self.batches) for i, xi in enumerate(xbatches) for yi in ybatches))\n",
    "            \n",
    "            print(self.raw.shape, \"after generating raw\")\n",
    "            \n",
    "            self.raw = np.reshape(self.raw, ((len(xbatches),len(ybatches),*self.raw.shape[1:])))\n",
    "\n",
    "            if self.plam.squeeze().ndim > 0:\n",
    "                self.raw = np.moveaxis(self.raw, get_param_axis(self.raw,self.plam.squeeze()), 0)\n",
    "\n",
    "            \n",
    "            if self.d.squeeze().ndim > 0:\n",
    "                self.raw = np.moveaxis(self.raw, get_param_axis(self.raw,self.d.squeeze()), 0)\n",
    "\n",
    "            self.raw = np.swapaxes(self.raw, -2,-3)\n",
    "            \n",
    "            print(self.raw.shape, \"before reshape\")\n",
    "            \n",
    "            self.raw = np.reshape(self.raw,(*(self.raw.shape[:-4]),len(self.x), len(self.y)))\n",
    "            \n",
    "            print(self.raw.shape, \"after reshape\")\n",
    "            \n",
    "            if self.sum_lam:\n",
    "                self.raw, self.plam = force_broadcast(self.raw,self.plam)\n",
    "                self.raw = np.sum(self.raw*self.plam, axis = get_param_axis(self.raw, self.plam.squeeze()))\n",
    "                \n",
    "            \n",
    "            for _ in range(self.raw.ndim - self.stepresx.ndim-1):\n",
    "                self.stepresx = np.expand_dims(self.stepresx, 0)\n",
    "                \n",
    "            self.stepresx = np.expand_dims(self.stepresx, -1)\n",
    "            # print(self.stepresx.shape)\n",
    "            \n",
    "            self.raw, self.stepresy = force_equal_dims(self.raw,self.stepresy)\n",
    "            # print(self.stepresy.shape)\n",
    "\n",
    "\n",
    "            if self.slityflag:\n",
    "                self.stepslity = generate_stepfunc(self.slity,self.ybin).squeeze()\n",
    "\n",
    "                self.raw, self.stepslity = force_equal_dims(self.raw,self.stepslity)\n",
    "                # print(self.stepslity.shape)   \n",
    "\n",
    "                \n",
    "                self.intensity = oaconvolve(self.raw,self.stepslity, mode = self.convmode, axes = -1)\n",
    "\n",
    "            if self.slitxflag:\n",
    "                self.stepslitx = generate_stepfunc(self.slitx,self.xbin).squeeze()\n",
    "\n",
    "                for _ in range(self.raw.ndim - self.stepslitx.ndim - 1):\n",
    "                    self.stepslitx = np.expand_dims(self.stepslitx, 0)\n",
    "                self.stepslitx = np.expand_dims(self.stepslitx, -1)\n",
    "                # print(self.stepslitx.shape)   \n",
    "\n",
    "                self.intensity = oaconvolve(self.intensity,self.stepslitx, mode = self.convmode, axes = -2)\n",
    "            # print(self.intensity.shape)   \n",
    "\n",
    "            \n",
    "            \n",
    "            if not (self.slitxflag and self.slityflag):\n",
    "                print(\"No slits\")\n",
    "                self.intensity = self.raw\n",
    "                                    \n",
    "            self.intensity = oaconvolve(oaconvolve(self.intensity, self.stepresy, mode = self.convmode, axes = -1),\\\n",
    "                                self.stepresx, mode = self.convmode, axes = -2)\n",
    "            # print(self.intensity.shape)\n",
    "            \n",
    "            self.intensity_x = np.sum(self.intensity, axis = -1)\n",
    "\n",
    "            # self.x = self.x[:self.intensity_x.shape[-1]]\n",
    "\n",
    "            \n",
    "            if type(Apparatus) == ForkGrating:\n",
    "               \n",
    "                self.fitparams_x = np.empty((*(self.intensity_x.shape[:-1]),4))\n",
    "\n",
    "                \n",
    "                if self.intensity_x.ndim < 3:\n",
    "                    for i in range(self.intensity_x.shape[0]):\n",
    "                        # clear_output(wait = True)\n",
    "                        # print(\"Fitting\")\n",
    "                        # print(\"%.2f %% done\" % (i/self.intensity.shape[0] * 1e2))\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        self.fitparams_x[i] = best_fit_moire_period(cosine_func, self.x, self.intensity_x[i],\\\n",
    "                                                self.p,self.L,self.d[i]) if len(self.d) > 1 \\\n",
    "                                                else best_fit_moire_period(cosine_func, self.x, self.intensity_x[i],\\\n",
    "                                                self.p,self.L,self.d)\n",
    "                        \n",
    "                \n",
    "                else:\n",
    "                    for i in range(self.intensity_x.shape[0]):\n",
    "                        clear_output(wait = True)\n",
    "                        print(\"Fitting\")\n",
    "                        print(\"%.2f %% done\" % (i/self.intensity_x.shape[0] * 1e2))\n",
    "\n",
    "                        for j in range(self.intensity_x.shape[1]):\n",
    "                            if self.d.squeeze().ndim > 1:\n",
    "                            \n",
    "                                params = best_fit_moire_period(cosine_func,self.x,self.intensity_x[i,j],self.p,self.L,self.d[i,j])\n",
    "                            else:\n",
    "\n",
    "                                params = best_fit_moire_period(cosine_func,self.x,self.intensity_x[i,j],self.p,self.L,self.d[i]) \n",
    "\n",
    "                            self.fitparams_x[i,j] = params\n",
    "\n",
    "                self.contrast = np.abs(self.fitparams_x[...,1]/self.fitparams_x[...,0])\n",
    "                return\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                self.intensity_y = np.sum(self.intensity, axis = -2)\n",
    "                \n",
    "                self.y = self.y[:self.intensity_y.shape[-1]]\n",
    "                \n",
    "                \n",
    "                self.fitparams_x = np.empty((*(self.intensity_x.shape[:-1]),4))\n",
    "                self.fitparams_y = np.empty((*(self.intensity_y.shape[:-1]),4))\n",
    "                \n",
    "                for i, d_i in enumerate(self.d.squeeze()):\n",
    "                    clear_output(wait = True)\n",
    "                    print(\"Fitting\")\n",
    "                    print(\"%.2f %% done\" % (i/self.d.shape[0] * 1e2))\n",
    "                    \n",
    "                    self.fitparams_x[i] = best_fit_moire_period(cosine_func, self.x, self.intensity_x[i],self.px,self.L, d_i)\n",
    "                    self.fitparams_y[i] = best_fit_moire_period(cosine_func, self.y, self.intensity_y[i],self.py,self.L, d_i)\n",
    "\n",
    "                \n",
    "                self.contrast_x = np.abs(self.fitparams_x[...,1]/self.fitparams_x[...,0])\n",
    "                self.contrast_y = np.abs(self.fitparams_y[...,1]/self.fitparams_y[...,0])\n",
    "\n",
    "                return\n",
    "        else:\n",
    "            self.raw = np.array(jb.Parallel(n_jobs = -1, prefer = \"threads\")(jb.delayed(Apparatus.generate_raw_intensity)(self.neu_spec,\\\n",
    "                                                    xi,i,self.batches) for i, xi in enumerate(xbatches)))\n",
    "\n",
    "            print(self.raw.shape, \"after parallel\")\n",
    "            if self.plam.squeeze().ndim > 0:\n",
    "                self.raw = np.moveaxis(self.raw, get_param_axis(self.raw,self.plam.squeeze()), 0)\n",
    "\n",
    "            \n",
    "            if self.d.squeeze().ndim > 0:\n",
    "                self.raw = np.moveaxis(self.raw, get_param_axis(self.raw,self.d.squeeze()), 0)\n",
    "                \n",
    "                \n",
    "            self.raw = np.reshape(self.raw,(*self.raw.shape[:-2], self.raw.shape[-2] * self.raw.shape[-1]))\n",
    "            print(self.raw.shape, \"after reshape\")\n",
    "            \n",
    "            if self.plam.squeeze().ndim > 0:\n",
    "                self.raw, self.plam = force_broadcast(self.raw,self.plam)\n",
    "                self.raw = np.sum(self.raw * self.plam, axis = get_param_axis(self.raw, self.plam.squeeze()))\n",
    "            \n",
    "#             plt.plot(self.raw[10])\n",
    "#             plt.show()\n",
    "            \n",
    "            if self.slitxflag:\n",
    "                self.stepslitx = generate_stepfunc(self.slitx,self.xbin).squeeze()\n",
    "\n",
    "                self.raw, self.stepslitx = force_equal_dims(self.raw,self.stepslitx)\n",
    "                \n",
    "            self.raw, self.stepresx = force_equal_dims(self.raw,self.stepresx)\n",
    "            print(self.raw.shape, \"before convolution\")\n",
    "            \n",
    "            if self.slitxflag: \n",
    "   \n",
    "                self.intensity = oaconvolve(oaconvolve(self.raw,self.stepslitx, mode = self.convmode, axes = -1),\\\n",
    "                                self.stepresx, mode = self.convmode, axes = -1)\n",
    "    \n",
    "            elif self.source_grating_flag:\n",
    "                self.raw, self.source_grating = force_equal_dims(self.raw, self.source_grating)\n",
    "                self.intensity = oaconvolve(oaconvolve(self.raw,self.source_grating, mode = self.convmode, axes = -1),\\\n",
    "                                self.stepresx, mode = self.convmode, axes = -1)\n",
    "            else:\n",
    "                self.intensity = oaconvolve(self.raw,self.stepresx, mode = self.convmode, axes = -1)\n",
    "            \n",
    "            \n",
    "\n",
    "            if self.intensity.shape[-1] > camsize/xbin:\n",
    "                self.intensity = self.intensity[...,:int(camsize/xbin)]\n",
    "\n",
    "            self.x = self.x[:self.intensity.shape[-1]]\n",
    "            self.fitparams = np.empty((*(self.intensity.shape[:-1]),4))\n",
    "\n",
    "            for i, d_i in enumerate(self.d.squeeze()):\n",
    "                clear_output(wait = True)\n",
    "                print(\"Fitting\")\n",
    "                print(\"%.2f %% done\" % (i/self.d.shape[0] * 1e2))\n",
    "                    \n",
    "                self.fitparams[i] = best_fit_moire_period(cosine_func, self.x, self.intensity[i],self.p,self.L, d_i)\n",
    "\n",
    "            \n",
    "            if self.Ioffset is not None:  \n",
    "                self.Ioffset, fitparams_offset = force_broadcast(self.Ioffset,self.fitparams[...,0])\n",
    "                # print(self.Ioffset.shape, fitparams_offset.shape)\n",
    "                fitparams_offset = fitparams_offset + self.Ioffset\n",
    "                fitparams_offset, unmodified_B = force_broadcast(fitparams_offset, self.fitparams[...,1])\n",
    "                self.contrast = np.abs(unmodified_B/fitparams_offset)\n",
    "\n",
    "            else:\n",
    "                self.contrast = np.abs(self.fitparams[...,1]/self.fitparams[...,0])\n",
    "            \n",
    "            return\n",
    "\n",
    "        \n",
    "class Grating:\n",
    "\n",
    "    def __init__(self,sd):\n",
    "        for key, value in sd.items():\n",
    "            setattr(self, key, assert_ndarr(value))\n",
    "        \n",
    "        self.L2, self.L1 = force_broadcast(self.L2, self.L1)\n",
    "        self.M = 1/(1 + self.L2/self.L1).squeeze()\n",
    "\n",
    "        if sd.get(\"x0\") is None:\n",
    "            self.x0 = 0\n",
    "\n",
    "\n",
    "class RectGrating(Grating):\n",
    "    \n",
    "    def __init__(self,sd):\n",
    "        super().__init__(sd)\n",
    "\n",
    "        self.is2d = False\n",
    "        \n",
    "        if sd.get(\"image_profile\") is not None:\n",
    "            self.profile = sd.get(\"image_profile\")\n",
    "\n",
    "            self.xpts = 10 * self.profile.shape[-1]\n",
    "            \n",
    "            \n",
    "            self.x0, self.x = force_broadcast(self.x0, np.linspace(-5*self.real_length,5*self.real_length, self.xpts))\n",
    "            self.x = np.squeeze(self.x - self.x0)\n",
    "            self.profile = normalize_profile(self.profile)\n",
    "\n",
    "            self.profile = np.interp(np.linspace(self.x[0],self.x[-1],self.xpts),self.x,np.tile(self.profile,10))\n",
    "\n",
    "            self.phi, self.profile = force_broadcast(self.phi, self.profile)\n",
    "            self.profile = self.phi / 2 * self.profile\n",
    "            self.real_length *= 10\n",
    "                        \n",
    "        else:\n",
    "            if sd.get(\"n_p_g\") is None:\n",
    "                self.n_p_g = 50\n",
    "            else:\n",
    "                self.n_p_g = self.n_p_g.squeeze()\n",
    "            \n",
    "            self.real_length = self.n_p_g * self.p\n",
    "            self.xpts = int(100*np.round(self.n_p_g) + 1)\n",
    "\n",
    "            # arbitrary number of points\n",
    "            self.x0, self.x = force_broadcast(self.x0, np.linspace(-self.real_length/2,self.real_length/2, self.xpts).T)\n",
    "            self.x = self.x - self.x0\n",
    "            self.p, self.phi, self.x = force_broadcast(self.p, self.phi, self.x)\n",
    "            self.profile = self.phi / 2 * grating_equation(self.x,self.p, 0 if sd.get(\"phase_offset\") is None else sd.get(\"phase_offset\"))\n",
    "            self.x = self.x.squeeze()\n",
    "            \n",
    "        \n",
    "        self.FT = fft(np.exp(1j*self.profile), axis = get_param_axis(self.profile,self.xpts),norm=\"forward\")\n",
    "        self.absFT = np.abs(self.FT)\n",
    "        self.freqs = get_freqs(self.FT, get_param_axis(self.FT, self.xpts), self.real_length)\n",
    "        ordrange = np.arange(-self.mt,self.mt+self.spectrum_spacing, self.spectrum_spacing)\n",
    "\n",
    "\n",
    "        self.p, ordrange = force_broadcast(self.p, ordrange)\n",
    "\n",
    "        self.ords = 2*np.pi/self.p * ordrange\n",
    "\n",
    "        self.ords, self.freqs = force_broadcast(self.ords, self.freqs)\n",
    "\n",
    "        self.locs = np.argmin(np.abs(self.freqs - self.ords),axis = get_param_axis(self.freqs, self.xpts))\n",
    "\n",
    "        self.FT, self.freqs = self.FT.squeeze(), self.freqs.squeeze()\n",
    "        dimdiff = self.FT.ndim - self.freqs.ndim\n",
    "        \n",
    "        # print(self.FT.shape,self.freqs.shape)\n",
    "        self.spectrum = np.squeeze([self.FT[...,np.unique(self.locs, axis = 0)],\\\n",
    "                        (np.tile(self.freqs,(*self.FT.shape[:dimdiff],*((1,)*(self.freqs.ndim)))))[...,np.unique(self.locs, axis = 0)]])\n",
    "        self.num_ords = len(ordrange)\n",
    "        # print(self.num_ords)\n",
    "    \n",
    "    def propagate(self,k0, neu_spec = None):\n",
    "        def B(k,k0):\n",
    "            return -k**2/(2*k0)\n",
    "        \n",
    "        ag,kg = self.spectrum.copy()\n",
    "\n",
    "\n",
    "        if neu_spec is None:\n",
    "            \n",
    "            self.M, self.L2, k0, a, k = force_broadcast(self.M, self.L2, k0, ag, kg)\n",
    "            # equivalent to convolving grating spectrum with identity\n",
    "\n",
    "        else:\n",
    "            a, k = neu_spec\n",
    "            \n",
    "            if np.any(np.array(a.shape) == (2*self.mt + 1)):\n",
    "                occurences = a.shape.count(2*self.mt + 1)\n",
    "\n",
    "                if self.spectrum_spacing != 1:\n",
    "                    a, k, ag, kg =  force_broadcast(a, k, ag, kg, nonunique_lengths=[2*self.mt + 1],\\\n",
    "                                    nonunique_occurrences=[occurences],desired_nonunique_arr_ax=\\\n",
    "                                    [np.vstack((np.tile([0,1],occurences),\\\n",
    "                                    np.repeat(np.arange(-occurences,0,1),2))).T])\n",
    "                elif occurences != self.apts_num:\n",
    "                    a, k, ag, kg =  force_broadcast(a, k, ag, kg, nonunique_lengths=[self.num_ords],\\\n",
    "                                    nonunique_occurrences=[occurences + 1],desired_nonunique_arr_ax=\\\n",
    "                                    [np.concatenate((np.vstack((np.tile([0,1],occurences),\\\n",
    "                                    np.repeat(np.arange(-occurences-1,-1,1),2))).T, [[-2,-1],[-1,-1]]))])\n",
    "                \n",
    "                else:\n",
    "                    a, k, ag, kg =  force_broadcast(a, k, ag, kg, nonunique_lengths=[self.num_ords],\\\n",
    "                                    nonunique_occurrences=[occurences+1],desired_nonunique_arr_ax=\\\n",
    "                                    [np.concatenate((np.vstack((np.tile([0,1],occurences-1),\\\n",
    "                                    np.repeat(np.arange(-occurences,-1,1),2))).T, [[-2,-1],[-1,-1]]))])\n",
    "\n",
    "            else:\n",
    "                a, k, ag, kg  = force_broadcast(a, k, ag, kg)\n",
    "            \n",
    "            \n",
    "            a = a * ag\n",
    "            k = k + kg\n",
    "                \n",
    "            occurences = a.shape.count(2*self.mt + 1)\n",
    "            # print_shapes(a,k,self.M, self.L2, k0)\n",
    "            self.M, self.L2, k0, a, k = force_broadcast(self.M, self.L2, k0, a, k, nonunique_lengths=[2*self.mt +1],\\\n",
    "                                        nonunique_occurrences=[occurences],desired_nonunique_arr_ax= \\\n",
    "                                        [np.vstack((np.tile([-2,-1],occurences), np.repeat(np.arange(-occurences,0,1),2))).T])\n",
    "            \n",
    "            # print(a.shape,k.shape,self.M.shape, self.L2.shape, k0.shape)\n",
    "            \n",
    "        self.a_prime = a*np.exp(-1j*B(k,k0)*self.M*self.L2)\n",
    "        self.k_prime = k*self.M\n",
    "        \n",
    "        return [self.a_prime, self.k_prime]\n",
    "    \n",
    "    def generate_raw_intensity(self,neu_spec,xarr, iteration, batches):\n",
    "        \n",
    "        \n",
    "        \n",
    "        a, k = neu_spec\n",
    "        \n",
    "        a, k = flatten_after_axis(a.squeeze(),k.squeeze(), axis = -self.apts_num)\n",
    "\n",
    "        \n",
    "        a, k, xarr = force_broadcast(a, k, xarr, nonunique_lengths= [a.shape[-1]],\\\n",
    "                                nonunique_occurrences= [1], desired_nonunique_arr_ax=\\\n",
    "                                [np.vstack([[0,1], [-1,-1]]).T])\n",
    "        \n",
    "        # # print(a.shape, k.shape,  xarr.shape)\n",
    "\n",
    "        psi = a * np.exp(-1j * (k*xarr))\n",
    "        print(\"Generating raw intensity, %.2f %% done\" % (100 * iteration/batches))    \n",
    "        clear_output(wait = True)\n",
    "\n",
    "        # print(psi.shape)\n",
    "        psi = np.sum(psi, axis = -1)\n",
    "\n",
    "        return np.abs(psi) * np.abs(psi)  \n",
    "            \n",
    "      \n",
    "            \n",
    "class RectGrating2D(Grating):\n",
    "    \n",
    "        \n",
    "    def __init__(self, sd):\n",
    "        super().__init__(sd)\n",
    "        \n",
    "        self.is2d = True\n",
    "        \n",
    "        if sd.get(\"n_p_g\") is None:\n",
    "                self.n_p_g = 50\n",
    "        else:\n",
    "            self.n_p_g = self.n_p_g.squeeze()\n",
    "\n",
    "        self.real_x_length = self.n_p_g * self.px\n",
    "        self.real_y_length = self.n_p_g * self.py\n",
    "\n",
    "        self.xpts = self.ypts = int(100*np.round(self.n_p_g) + 1)\n",
    "\n",
    "        self.x, self.y = (np.linspace([-self.real_x_length/2,-self.real_y_length/2],\\\n",
    "                        [self.real_x_length/2,self.real_y_length/2],self.xpts)).squeeze().T\n",
    "        \n",
    "\n",
    "        self.phi, self.x, self.y = force_broadcast(self.phi, self.x, self.y, nonunique_lengths= [self.xpts],\\\n",
    "                                    nonunique_occurrences= [2], desired_nonunique_arr_ax= [np.vstack([[-2,-1],[-2,-1]]).T])\n",
    "\n",
    "        self.profile = self.phi/2 * grating_equation_2d(self.x,self.y,self.px,self.py)\n",
    "        \n",
    "        # c = plt.imshow(self.profile, clim = (0,1e-3))\n",
    "        # plt.colorbar(c)\n",
    "        # plt.show()\n",
    "        \n",
    "        self.FT = fft2(np.exp(1j*self.profile), axes = (-2,-1), norm = \"forward\")\n",
    "        self.absFT = np.abs(self.FT)\n",
    "        \n",
    "        \n",
    "        self.xfreqs = get_freqs(self.FT, get_param_axis(self.FT,self.xpts), self.real_x_length)\n",
    "        self.yfreqs = get_freqs(self.FT, get_param_axis(self.FT,self.ypts), self.real_y_length)\n",
    "        \n",
    "        \n",
    "        # c = plt.imshow(self.absFT, clim = (0,1e-3), extent = (np.min(self.xfreqs), np.max(self.xfreqs), np.min(self.yfreqs), np.max(self.yfreqs)))\n",
    "        # plt.colorbar(c)\n",
    "        # plt.vlines((2*pi/self.px,-2*pi/self.px) , ymin = -1e8, ymax = 1e8, lw = 1, color = \"r\")\n",
    "        # plt.hlines((2*pi/self.py,-2*pi/self.py) , xmin = -1e8, xmax = 1e8, lw = 1, color = \"r\")\n",
    "        # plt.xlim(-8*pi/self.px,8*pi/self.px)\n",
    "        # plt.ylim(-8*pi/self.py,8*pi/self.py)\n",
    "        # plt.show()\n",
    "        \n",
    "        self.xords = 2*np.pi/self.px * np.arange(-self.mt,self.mt+self.spectrum_spacing,self.spectrum_spacing)\n",
    "        self.yords = 2*np.pi/self.py * np.arange(-self.mt,self.mt+self.spectrum_spacing,self.spectrum_spacing)\n",
    "\n",
    "        self.xlocs = np.argmin(np.abs(self.xfreqs[:,None] - self.xords[None,:]),axis = get_param_axis(self.xfreqs,self.xpts))\n",
    "        self.ylocs = np.argmin(np.abs(self.yfreqs[:,None] - self.yords[None,:]),axis = get_param_axis(self.yfreqs,self.ypts))\n",
    "        \n",
    "\n",
    "        self.xylocs = tuple(np.split(np.array(np.meshgrid(self.xlocs,self.ylocs)).ravel(),2))\n",
    "        # self.spectrum = [self.FT[...,self.xylocs[0],self.xylocs[1]],self.xfreqs[self.xlocs], self.yfreqs[self.ylocs]]\n",
    "        \n",
    "        # print(self.spectrum[0].shape)\n",
    "        dimdiff = self.FT.ndim - self.xfreqs.ndim\n",
    "        \n",
    "        self.spectrum = [self.FT[...,self.xylocs[0],self.xylocs[1]],\\\n",
    "                        np.tile(self.xfreqs[self.xlocs],(*self.FT.shape[:dimdiff - 1],*((1,)*(self.xfreqs.ndim)))),\\\n",
    "                        np.tile(self.yfreqs[self.ylocs],(*self.FT.shape[:dimdiff - 1],*((1,)*(self.yfreqs.ndim))))]\n",
    "        # print(self.spectrum[0].shape, self.spectrum[1].shape, self.spectrum[2].shape)\n",
    "\n",
    "        self.num_ords = len(self.xords)\n",
    "\n",
    "            \n",
    "    def propagate(self,k0,neu_spec = None):\n",
    "        def B(kx,ky,k0):\n",
    "            return -(kx**2 + ky**2)/(2*k0)\n",
    "        \n",
    "        ag, kgx, kgy = self.spectrum.copy()\n",
    "        \n",
    "        ag = ag.reshape((*ag.shape[:-1],kgx.shape[-1], kgy.shape[-1]))\n",
    "        \n",
    "\n",
    "        if neu_spec is None:\n",
    "            \n",
    "            self.M, self.L2, k0, a, kx, ky = force_broadcast(self.M, self.L2, k0, ag, kgx, kgy,\\\n",
    "                                            nonunique_lengths= [self.num_ords], nonunique_occurrences=[2*self.apts_num],\\\n",
    "                                            desired_nonunique_arr_ax=[np.vstack(([-3,-3,-2,-1], np.tile([-2,-1],2))).T])\n",
    "            # equivalent to convolving grating spectrum with identity\n",
    "        else:\n",
    "            \n",
    "            a, kx, ky = neu_spec\n",
    "            \n",
    "            \n",
    "            # print(a.shape, kx.shape, ky.shape, ag.shape,kgx.shape,kgy.shape)\n",
    "            \n",
    "            a, kx, ky, ag, kgx, kgy =  force_broadcast(a, kx, ky, ag, kgx, kgy, nonunique_lengths=[self.num_ords],\\\n",
    "                                        nonunique_occurrences=[2*self.apts_num], desired_nonunique_arr_ax = \\\n",
    "                                        [np.vstack([np.concatenate([np.tile([*([0]*(2*(self.apts_num -1))),1,2],self.apts_num-1),\\\n",
    "                                        [*([-3]*(2*(self.apts_num -1))),-2,-1]]), np.concatenate([np.delete(np.tile(np.arange(-2*self.apts_num,0),2),\\\n",
    "                                        np.arange(4)*-self.apts_num -1), np.tile([-self.apts_num -1,-1],2)])]).T])\n",
    "            # print(a.shape, kx.shape, ky.shape, ag.shape,kgx.shape,kgy.shape)\n",
    "            # ensures that x and y amplitudes (as opposed to n,m,l,... orders) remain together for later flattening\n",
    "\n",
    "            # [-4,-2,-4,-2] [-3,-1,-3,-1]\n",
    "            # [-6,-5,-3,-2,-6,-5,-3,-2] [-4,-1,-4,-1]\n",
    "            a = a * ag\n",
    "            kx = kx + kgx\n",
    "            ky = ky + kgy\n",
    "            \n",
    "            # print(self.M.shape, self.L2.shape, k0.shape, a.shape,kx.shape,ky.shape)\n",
    "            \n",
    "            self.M, self.L2, k0, a, kx, ky = force_broadcast(self.M, self.L2, k0, a, kx, ky, nonunique_lengths= [self.num_ords],\\\n",
    "                                            nonunique_occurrences=[2*self.apts_num],desired_nonunique_arr_ax=\\\n",
    "                                            [np.vstack([np.append(np.repeat(-3,2*self.apts_num),np.repeat([-2,-1],self.apts_num)),\\\n",
    "                                            np.tile(np.arange(-2*self.apts_num,0,1),2)]).T])\n",
    "            # print(self.M.shape, self.L2.shape, k0.shape, a.shape,kx.shape,ky.shape)\n",
    "\n",
    "            \n",
    "        self.a_prime = a*np.exp(-1j*B(kx,ky,k0)*self.M*self.L2)\n",
    "        self.kx_prime = kx*self.M\n",
    "        self.ky_prime = ky*self.M\n",
    "\n",
    "        return [self.a_prime, self.kx_prime, self.ky_prime]\n",
    "    \n",
    "    def generate_raw_intensity(self,neu_spec,xarr,yarr, iteration, batches):\n",
    "        \n",
    "        \n",
    "        \n",
    "        a, kx, ky = neu_spec\n",
    "        # print(a.shape, kx.shape, ky.shape)\n",
    "        \n",
    "        kx, ky = flatten_after_axis(kx.squeeze(),ky.squeeze(), axis = -self.apts_num)\n",
    "        a = flatten_after_axis_2d(a,axis = -self.apts_num)\n",
    "        # print(a.shape, kx.shape, ky.shape)\n",
    "\n",
    "        \n",
    "        a, kx, ky, xarr, yarr = force_broadcast(a, kx, ky, xarr, yarr, nonunique_lengths= [a.shape[-1]],\\\n",
    "                                nonunique_occurrences= [2], desired_nonunique_arr_ax=\\\n",
    "                                [np.vstack([[0,0,1,2], [-2,-1,-2,-1]]).T])\n",
    "        \n",
    "        # print(a.shape, kx.shape, ky.shape, xarr.shape, yarr.shape)\n",
    "\n",
    "        psi = a * np.exp(-1j * (kx*xarr + ky*yarr))\n",
    "        print(\"Generating raw intensity, %.2f %% done\" % (100 * iteration/batches))    \n",
    "        clear_output(wait = True)\n",
    "\n",
    "        # print(psi.shape)\n",
    "        psi = np.sum(psi, axis = (-2,-1))\n",
    "\n",
    "        return np.abs(psi) * np.abs(psi)\n",
    "    \n",
    "    \n",
    "\n",
    "class SphericalSample(Grating):\n",
    "    \n",
    "    \n",
    "    def __init__(self,sd):\n",
    "        super().__init__(sd)\n",
    "        \n",
    "        self.is2d = False\n",
    "        \n",
    "        def sphere_profile(x,r_sphere):\n",
    "            return np.real(2*np.sqrt(r_sphere**2 - x**2)) / r_sphere\n",
    "        \n",
    "        testind = -1\n",
    "        \n",
    "        if sd.get(\"n_p_g\") is None:\n",
    "            self.n_p_g = 50\n",
    "        else:\n",
    "            self.n_p_g = self.n_p_g.squeeze()\n",
    "            \n",
    "        # self.real_length = self.p_s\n",
    "        self.real_length = self.n_p_g * self.p_g\n",
    "        self.xpts = int(100*np.round(self.n_p_g) + 1 )\n",
    "        # print(self.real_length, self.xpts)\n",
    "        \n",
    "        self.x = np.linspace(-self.real_length/2,self.real_length/2, self.xpts).T.astype(complex)\n",
    "\n",
    "        # self.x = fftshift(np.roll(self.x,1,axis = get_param_axis(self.x,self.xpts)), axes = get_param_axis(self.x,self.xpts))\n",
    "\n",
    "            \n",
    "        self.x0, self.x = force_broadcast(self.x0, self.x)\n",
    "        self.x = self.x - self.x0\n",
    "        self.phi, self.r_sphere, self.x = force_broadcast(self.phi,self.r_sphere, self.x)\n",
    "        \n",
    "        self.profile = sphere_profile(self.x,self.r_sphere)\n",
    "        self.x = self.x.squeeze()\n",
    "        \n",
    "        \n",
    "#         plt.plot(self.profile[0], \"o\")\n",
    "#         plt.show()\n",
    "        \n",
    "#         plt.plot(self.profile[-1], \"o\")\n",
    "#         plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.FT = fft(np.exp(1j * self.phi * self.profile), axis = get_param_axis(self.profile,self.xpts),norm=\"forward\")\n",
    "\n",
    "\n",
    "        self.freqs = np.real_if_close(get_freqs(self.FT, get_param_axis(self.FT, self.xpts), self.real_length))\n",
    "\n",
    "        \n",
    "        # print(self.freqs.shape)\n",
    "        # plt.plot(self.freqs.squeeze(), np.abs(self.FT), \"o\")\n",
    "        # plt.show()\n",
    "\n",
    "        crop = (np.abs(self.FT) > 1e-4).squeeze()\n",
    "\n",
    "        if crop.ndim > 1:\n",
    "            crop = np.any(crop, axis = get_param_axis(crop,self.r_sphere))\n",
    "\n",
    "            \n",
    "        if np.any(np.array(retain_shape_after_index(self.freqs, crop).shape) == 1):\n",
    "            crop = (np.abs(self.freqs) < np.pi/self.r_sphere / self.n_p_g).squeeze()\n",
    "            \n",
    "    \n",
    "        self.freqs, self.FT = retain_shape_after_index(self.freqs, crop), retain_shape_after_index(self.FT,crop)\n",
    "        # print(self.freqs.shape)\n",
    "\n",
    "        \n",
    "        # plt.plot(self.freqs.squeeze(), np.abs(self.FT), \"o\")\n",
    "        # plt.show()\n",
    "        \n",
    "#         plt.plot(self.freqs.squeeze(), np.abs(self.FT[-1]), \"o\")\n",
    "#         plt.show()\n",
    "        \n",
    "    \n",
    "        self.FT, self.freqs = self.FT.squeeze(), self.freqs.squeeze()\n",
    "        dimdiff = self.FT.ndim - self.freqs.ndim\n",
    "        self.freqs = np.tile(self.freqs, (*self.FT.shape[:dimdiff],*((1,)*(self.freqs.ndim))))\n",
    "        \n",
    "\n",
    "        self.absFT = np.abs(self.FT)\n",
    "        \n",
    "        # plt.plot(self.freqs[testind],self.absFT[testind], \"o\")\n",
    "        # plt.show()\n",
    "        \n",
    "        self.spectrum = np.squeeze([self.FT,self.freqs])\n",
    "        \n",
    "        self.num_ords = self.FT.shape[-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def propagate(self,k0, neu_spec = None):\n",
    "        def B(k,k0):\n",
    "            return -k**2/(2*k0)\n",
    "        \n",
    "        a_sample,k_sample = self.spectrum.copy()\n",
    "        \n",
    "        if neu_spec is None:\n",
    "            \n",
    "            self.M, self.L2, k0, a, k = force_broadcast(self.M, self.L2, k0, a_sample, k_sample)\n",
    "           \n",
    "\n",
    "        else:\n",
    "            a, k = neu_spec\n",
    "            \n",
    "            unique_shape = np.unique(a.shape)\n",
    "            dup_flag = False\n",
    "            if len(a.shape) != len(unique_shape):\n",
    "\n",
    "                dup_occurences = len(a.shape) - len(unique_shape) + 1\n",
    "                occurences = np.array([a.shape.count(x) for x in unique_shape])\n",
    "                dup_val = np.array(unique_shape)[occurences > 1].squeeze()\n",
    "\n",
    "                \n",
    "                if self.num_ords in a.shape:\n",
    "                    dup_flag = True\n",
    "                    a, k, a_sample, k_sample =  force_broadcast(a, k, a_sample, k_sample, nonunique_lengths=[dup_val],\\\n",
    "                                                nonunique_occurrences=[dup_occurences + 1],desired_nonunique_arr_ax=\\\n",
    "                                                [np.vstack((np.concatenate((np.tile([0,1],self.apts_num-1),[-2,-1])),\\\n",
    "                                                np.concatenate((np.repeat(np.arange(-self.apts_num+1,0,1),2), [-self.apts_num,-self.apts_num])))).T])\n",
    "                else:\n",
    "                    a, k, a_sample, k_sample =  force_broadcast(a, k, a_sample, k_sample, nonunique_lengths=[dup_val],\\\n",
    "                                                nonunique_occurrences=[dup_occurences],desired_nonunique_arr_ax=\\\n",
    "                                                [np.vstack((np.tile([0,1],self.apts_num-1),\\\n",
    "                                                np.repeat(np.arange(-self.apts_num+1,0,1),2))).T])\n",
    "\n",
    "            else:\n",
    "                a, k, a_sample, k_sample  = force_broadcast(a, k, a_sample, k_sample)\n",
    "            \n",
    "            a = a * a_sample\n",
    "            k = k + k_sample\n",
    "            \n",
    "            print(a.shape,k.shape,self.M.shape, self.L2.shape, k0.shape)\n",
    "            if dup_flag:\n",
    "                self.M, self.L2, k0, a, k = force_broadcast(self.M, self.L2, k0, a, k, nonunique_lengths=[dup_val],\\\n",
    "                                            nonunique_occurrences=[dup_occurences+1],desired_nonunique_arr_ax=\\\n",
    "                                            [np.vstack((np.tile([-2,-1],self.apts_num),\\\n",
    "                                            np.repeat(np.arange(-self.apts_num,0,1),2))).T])\n",
    "            else:\n",
    "                self.M, self.L2, k0, a, k = force_broadcast(self.M, self.L2, k0, a, k, nonunique_lengths=[dup_val],\\\n",
    "                                            nonunique_occurrences=[dup_occurences],desired_nonunique_arr_ax=\\\n",
    "                                            [np.vstack((np.tile([-2,-1],self.apts_num-1),\\\n",
    "                                            np.repeat(np.arange(-self.apts_num+1,0,1),2))).T])\n",
    "            \n",
    "            # print(a.shape,k.shape,self.M.shape, self.L2.shape, k0.shape)\n",
    "            \n",
    "        self.a_prime = a*np.exp(-1j*B(k,k0)*self.M*self.L2)\n",
    "        self.k_prime = k*self.M\n",
    "        return [self.a_prime, self.k_prime]\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "class ForkGrating(RectGrating):\n",
    "   \n",
    "    def __init__(self,sd):\n",
    "        super().__init__(sd)\n",
    "        self.is2d = True\n",
    "        \n",
    "        \n",
    "        \n",
    "    def generate_raw_intensity(self,neu_spec,xarr,yarr, iteration, batches):\n",
    "        a, k = neu_spec\n",
    "        \n",
    "        print(\"Generating raw intensity, %.2f %% done\" % (100 * iteration/batches))\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        OAMorders = np.roll(fftshift(np.arange(-self.mt,self.mt+self.spectrum_spacing,self.spectrum_spacing) * self.OAM), 1)\n",
    "\n",
    "        phase = np.arctan2(yarr[None,...],xarr[...,None])\n",
    "\n",
    "        \n",
    "        # fork_phase = OAMorders[None,None,None,None,:] * phase[None,:,:,None,None]  \n",
    "        # a, k = a[:,None,None,...], k[:,None,None,...]\n",
    "        # xarr = xarr[None,:,None,None,None]\n",
    "        \n",
    "        fork_phase = OAMorders[...,:] * phase[...,None]\n",
    "        a, k, xarr, fork_phase = a[None,None, :,:], k[None,None,:,:], xarr[:,None,None,None], fork_phase[:,:,None,:]\n",
    "        psi = np.sum(a * np.exp(-1j * k * xarr) * np.exp(-1j*fork_phase), axis = (-2,-1))\n",
    "        \n",
    "        return np.abs(psi) * np.abs(psi)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class RotatedProfile:\n",
    "    \n",
    "    def __init__(self,deg, profile, profile_size,profile_height, profile_period):\n",
    "        self.deg = assert_ndarr(deg)\n",
    "\n",
    "        self.extended_profile = np.tile(profile,3)\n",
    "        extended_shape = self.extended_profile.shape[0]\n",
    "        height_in_pts = round(profile.shape[0] * profile_height // (profile_size))\n",
    "        self.background = np.zeros((extended_shape,height_in_pts), dtype = np.int8)\n",
    "        self.scaled_profile = (self.extended_profile - np.min(self.extended_profile) - 1/height_in_pts) / (np.max(self.extended_profile) - np.min(self.extended_profile)) \n",
    "\n",
    "        for col_ind, col in enumerate(self.background):\n",
    "            self.background[col_ind,:int(self.scaled_profile[col_ind]*height_in_pts)+2] = 1\n",
    "\n",
    "        self.rotated = [rotate(self.background,-d) for d in self.deg]\n",
    "        self.summed = [np.sum(rot,axis = -1) for rot in self.rotated]\n",
    "\n",
    "        self.scaled_summed = [2*(s - np.min(s))/(np.max(s) - np.min(s)) - 1 for s in self.summed]\n",
    "\n",
    "        self.rotated_profiles = [s[extended_shape//3:2*extended_shape//3] for s in self.scaled_summed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3904344-d59b-451a-936e-4c02d095c011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
