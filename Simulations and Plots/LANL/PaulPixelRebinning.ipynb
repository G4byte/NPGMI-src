{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a11c93-5abd-45af-b38c-dc003353c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %title Rebinning with deadtime correction and caching: fetch_timepix_frame\n",
    "# Pixelman FITS header from LANL:asterix camera\n",
    "# SIMPLE  =                    T / file does conform to FITS standard             \n",
    "# BITPIX  =                   16 / number of bits per data pixel                  \n",
    "# NAXIS   =                    2 / number of data axes                           \n",
    "# NAXIS1  =                  512 / length of data axis 1                          \n",
    "# NAXIS2  =                  512 / length of data axis 2                          \n",
    "# EXTEND  =                    T / FITS dataset may contain extensions            \n",
    "# COMMENT   FITS (Flexible Image Transport System) format is defined in 'Astronomy\n",
    "# COMMENT   and Astrophysics', volume 376, page 359; bibcode: 2001A&A...376..359H \n",
    "# TOF     =   0.0399830399999987 / Ttime of flight from the external trigger      \n",
    "# TIMEBIN =           1.536E-005 / Time width of this image                       \n",
    "# N_COUNTS=               756805 / Total counts in this image                     \n",
    "# N_TRIGS =                10000 / Number of triggers acquired                    \n",
    "# TEST1   = 'One_Continuous_Word_here' / Comment1                                 \n",
    "# TEST2   = '14.567  '           / Comment                                        \n",
    "#\n",
    "# Note: imagemagick convert to tiff doesnt preserve the special tags:\n",
    "#    TOF, TIMEBIN, N_COUNTS, N_TRIGS\n",
    "\n",
    "def rebin_timepix_dataset(path, bins=None, outpath=None):\n",
    "    print(f\"Rebinning {str(path)}...\")\n",
    "    dtype = torch.float32\n",
    "    # Note: if there is an exception during the following loop\n",
    "    # (e.g., from an interrupt), then the TimepixWriter context\n",
    "    # manager exit will delete the outpath that was being built.\n",
    "    # This is not a complete abort. If the caller created the\n",
    "    # leading path elements (e.g., SiGrating/Open) then the interrupt\n",
    "    # during the first file will still leave the created path on disk.\n",
    "    with (\n",
    "        TimepixReader(path, dtype=dtype) as tpx, \n",
    "        TimepixWriter(outpath) as out\n",
    "    ):\n",
    "        # Move to the first bin\n",
    "        index = 0\n",
    "        start, end = (index, index+1) if bins is None else bins[index]\n",
    "        \n",
    "        # Cycle through the frames\n",
    "        for k, header, data in tpx:\n",
    "            # Accumulate probability and correct the frame\n",
    "            gdata = util.to_cuda(torch.as_tensor(data))\n",
    "            Δp = gdata/header['N_TRIGS']\n",
    "            if k == 0:\n",
    "                corrected = gdata\n",
    "                p = Δp\n",
    "            else:\n",
    "                corrected = gdata / (1 - p)\n",
    "                p += Δp\n",
    "                del gdata, Δp\n",
    "\n",
    "            # Accumulate bin\n",
    "            if k == start:\n",
    "                gbinned = corrected\n",
    "                tof = header['TOF']\n",
    "                timebin = header['TIMEBIN']\n",
    "            elif start < k < end:\n",
    "                gbinned += corrected\n",
    "                timebin += header['TIMEBIN']\n",
    "                del corrected\n",
    "\n",
    "            if k+1 == end:                    \n",
    "                # Save bin\n",
    "                tags = {'TOF': tof, 'TIMEBIN': timebin, 'N_TRIGS': header['N_TRIGS']}\n",
    "                binned = gbinned.cpu()\n",
    "                out.write(index, binned, tags)\n",
    "\n",
    "                # Accumulate SummedImg\n",
    "                if index == 0:\n",
    "                    summed_image = binned\n",
    "                    summed_tags = tags\n",
    "                    #spectra = []\n",
    "                else:\n",
    "                    summed_image += binned\n",
    "                    summed_tags['TIMEBIN'] += tags['TIMEBIN']\n",
    "                #spectra.append((tags['TOF'], binned.sum()))\n",
    "                \n",
    "                # Move to next bin\n",
    "                index += 1\n",
    "                if bins is None:\n",
    "                    start, end = index, index+1\n",
    "                elif index < len(bins):\n",
    "                    start, end = bins[index]\n",
    "                else:\n",
    "                    # No more bins. No need to read the remaining frames.\n",
    "                    break\n",
    "                start, end = (index, index+1) if bins is None else bins[index]\n",
    "\n",
    "        # TODO: Write {ShutterCount,ShutterTimes,Spectra,Status}.txt ?\n",
    "        # Save summed image\n",
    "        out.write('sum', summed_image, summed_tags)\n",
    "\n",
    "    del p, summed_image, summed_tags\n",
    "\n",
    "class TimepixWriter:\n",
    "    def __init__(self, path):\n",
    "        from zipfile import ZipFile, ZIP_DEFLATED\n",
    "        path = Path(path).expanduser()\n",
    "        # TODO: Preserve timestamps on original data?\n",
    "        zf = None\n",
    "        if path.suffix == '.zip':\n",
    "            zf = ZipFile(path, 'w', compression=ZIP_DEFLATED, compresslevel=9)\n",
    "            handle = lambda f: zf.open(f, mode='w')\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Only write timepix to .zip, not {str(path)}\")\n",
    "            \n",
    "        self._path = path\n",
    "        self._zf = zf\n",
    "        self._handle = handle\n",
    "        self._basename = path.stem\n",
    " \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        self.close()\n",
    "        # TODO: maybe the unlinking belongs in the rebin code rather than the context manager?\n",
    "        # If we died with any sort of exception, then remove the 'in progress' zip file.\n",
    "        if exc_type is not None:\n",
    "            self._path.unlink()\n",
    "        return False\n",
    "\n",
    "    def close(self):\n",
    "        if self._zf is not None:\n",
    "            self._zf.close()\n",
    "            self._zf = None\n",
    "\n",
    "    def write(self, index, data, tags):\n",
    "        from astropy.io import fits\n",
    "        n_counts = float(data.sum())\n",
    "        data = data.numpy()\n",
    "        # TODO: Check data format before writing to'>f4'?\n",
    "        data = np.asarray(data, dtype='>f4')\n",
    "        hdu = fits.PrimaryHDU(data)\n",
    "        #for k, v in tags.items(): hdu.header[k] = v   # tags don't have labels\n",
    "        hdu.header['TOF'] = (tags['TOF'], \"Time of flight from the external trigger\")\n",
    "        hdu.header['TIMEBIN'] = (tags['TIMEBIN'], \"Time width of this image\")\n",
    "        hdu.header['N_COUNTS'] = (n_counts, \"Total counts in this image\")\n",
    "        hdu.header['N_TRIGS'] = (tags['N_TRIGS'], \"Number of triggers acquired\")\n",
    "        hdul = fits.HDUList([hdu])\n",
    "        \n",
    "        label = 'SummedImg' if index == 'sum' else f'{index:05d}'\n",
    "        filename = f\"{self._basename}_{label}.fits\"\n",
    "        with self._handle(filename) as fd:\n",
    "            hdul.writeto(fd)            \n",
    "\n",
    "class TimepixReader:\n",
    "    def __init__(self, path, dtype=None):\n",
    "        from zipfile import ZipFile\n",
    "        from fnmatch import fnmatch\n",
    "\n",
    "        path = Path(path).expanduser()\n",
    "        if path.suffix == '.zip' and not path.is_dir():\n",
    "            # TODO: We should close the zip file in case of loader exception.\n",
    "            zf = ZipFile(path)\n",
    "            files = [f for f in sorted(zf.namelist()) if fnmatch(f, '*.fits')]\n",
    "            handle = lambda f: zf.open(f)\n",
    "        else:\n",
    "            if path.is_dir():\n",
    "                pattern = '*.fits'\n",
    "                parent = path\n",
    "            elif path.suffix == '.fits':\n",
    "                pattern = path.name.rsplit('_', 1)[0] + '_*.fits'\n",
    "                parent = path.parent\n",
    "            else:\n",
    "                pattern = path.name + '*.fits'\n",
    "                parent = path.parent\n",
    "            zf = None\n",
    "            files = sorted(parent.glob(pattern))\n",
    "            handle = lambda f: fits.open(f)\n",
    "        if not files:\n",
    "            raise RuntimeError(f\"No dataset matches {path}\")\n",
    "\n",
    "        if 'SummedImg' in files[-1]:\n",
    "            summed = files[-1]\n",
    "            files = files[:-1]\n",
    "        else:\n",
    "            warnings.warn(f\"No summed image in {path}\")\n",
    "            summed = None\n",
    "\n",
    "        # Find frame files from directory listing\n",
    "        #indexed = [(index, f) for f in files if index := _timepix_index(f) is not None]\n",
    "        indexed = [(index, f) for f in files for index in [_timepix_index(f)] if index is not None]\n",
    "        # Make sure files are in index order with no frames missing\n",
    "        for k, f in enumerate(files):\n",
    "            if k != _timepix_index(f):\n",
    "                raise RuntimeError(f\"Missing time slice {k} in dataset {path}\")\n",
    "\n",
    "        self._zf = zf\n",
    "        self._handle = handle\n",
    "        self._files = files\n",
    "        self._summed = summed\n",
    "        self._dtype = None if dtype is None else util.numpy_native(util.numpy_dtype(dtype))\n",
    "        \n",
    "    @property\n",
    "    def num_slices(self):\n",
    "        return len(self._files)\n",
    " \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        self.close()\n",
    "        return False\n",
    "    \n",
    "    def close(self):\n",
    "        if self._zf is not None:\n",
    "            self._zf.close()\n",
    "            self._zf = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        for k in range(self.num_slices):\n",
    "            header, data = self.read(k)\n",
    "            yield k, header, data\n",
    "        \n",
    "    def read(self, index):\n",
    "        from astropy.io import fits\n",
    "        filename = self._summed if index in ('SummedImg', 'sum') else self._files[index]\n",
    "        h = fits.open(self._handle(filename))\n",
    "        header, data = h[0].header, h[0].data.T\n",
    "        h.close()\n",
    "        dtype = util.numpy_native(data.dtype) if self._dtype is None else self._dtype\n",
    "        return header, np.asarray(data, dtype=dtype)\n",
    "\n",
    "def _timepix_index(name):\n",
    "    \"\"\"Convert filename to ToF index\"\"\"\n",
    "    tail = name.rsplit('_', 1)[1]\n",
    "    strval = tail.split('.', 1)[0]\n",
    "    try:\n",
    "        return int(strval)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def fetch_timepix_frame(path, t, dark_rate=None, missing_ok=False):\n",
    "    path = Path(path)\n",
    "    if path.is_absolute():\n",
    "        try:\n",
    "            path = path.relative_to(DATAPATH)\n",
    "        except ValueError:\n",
    "            raise RuntimeError(f\"Can't cache full path {path}\")\n",
    "\n",
    "    rawpath = DATAPATH / path\n",
    "    binpath = BINNEDPATH / path\n",
    "    if not binpath.exists() and not rawpath.exists():\n",
    "        # Missing data\n",
    "        if not missing_ok:\n",
    "            raise ValueError(f\"No data in {str(rawpath)}\")\n",
    "        data = torch.zeros((512,512), dtype=torch.float32)\n",
    "        data.header = dotted(TOF=0., TIMEBIN=1e-5, N_TRIGS=0, BACKGROUND=0, path=path, t=t)\n",
    "        return data\n",
    "        \n",
    "    if not binpath.exists():\n",
    "        binpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        rebin_timepix_dataset(rawpath, bins=BINS.index, outpath=binpath)\n",
    "\n",
    "    if dark_rate is None:\n",
    "        dark_rate = (DARK_RATE if 'DARK_RATE' in globals() else 0.)\n",
    "    with TimepixReader(binpath, torch.float32) as fd:\n",
    "        header, data = fd.read(t)\n",
    "        tof, timebin, n_trigs = header['TOF'], header['TIMEBIN'], header['N_TRIGS']\n",
    "        data = torch.as_tensor(data.T)\n",
    "        duration = timebin*n_trigs\n",
    "        background = dark_rate*duration\n",
    "        data.header = dotted(TOF=tof, TIMEBIN=timebin, N_TRIGS=n_trigs, BACKGROUND=background, path=path, t=t)\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
